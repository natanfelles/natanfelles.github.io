---
title:  "HTTrack - Copiador de Websites"
categories: desenvolvimento
tags: httrack linux
image: httrack.png
description: HTTrack lhe permite fazer download de sites na internet para um diretório local, criando recursivamente todos os diretórios, pegando arquivos HTML, imagens e outros arquivos do servidor para o seu computador. HTTrack organiza a estrutura original de links dos sites. Simplesmente abra a página espelhada em seu navegador e você poderá navegar de página em página, como se estivesse no site original. HTTrack também pode atualizar sites já copiados e continuar downloads interrompidos.
---

## Sobre

HTTrack lhe permite fazer download de sites na internet para um diretório local, criando recursivamente todos os diretórios, pegando arquivos HTML, imagens e outros arquivos do servidor para o seu computador. HTTrack organiza a estrutura original de links dos sites. Simplesmente abra a página "espelhada" em seu navegador e você poderá navegar de página em página, como se estivesse no site original. HTTrack também pode atualizar sites já copiados e continuar downloads interrompidos.

## Uso

Como visto, este software pode ser usado para devidos fins e não, ele não copia páginas protegidas por autenticação, nem mesmo bancos de dados, somente o conteúdo estático.

Em tempos de crise (e até por preferência pessoal), trabalho sem conexão com a internet. Há vários motivos, mas principalmente por causa da distração em canais de comunicação. E devido a esses fatos acho o HTTrack muito importante para poder ter exemplos de sites e páginas de documentação localmente.

~~Inclusive, tenho esse site em meu servidor local. Construído em PHP e MySQL. Mas como o GitHub não executa arquivos dinâmicos, copio tudo com o HTTrack e atualizo o repositório remoto quando quero.~~

## Instalação

Para instalá-lo é muito simples. Você pode encontrá-lo no Synaptic ou simplesmente executar:

```sh
sudo apt install httrack
```

## Comandos

Lembrando que sempre que você instalar um novo software e quiser ver seus possíveis comandos você pode consultar sua [manpage]({{ site.baseurl }}{% post_url 2016-01-24-manpages-coloridas-portugues %}).

Você pode rodar apenas **httrack** para configurar o espelhamento de maneira interativa ou já passar os parâmetros conforme abaixo:

```sh
httrack --preserve --footer "" https://natanfelles.github.io
```

~~Este é o comando que utilizo para espelhar meu site local antes de sincronizá-lo com o GitHub.~~ Os dois parâmetros iniciais são utilizados para não adicionar os comentários automáticos do HTTrack, de tal forma que o código será idêntico ao do site copiado.

Caso o site que você queira copiar possua arquivos estáticos em outro domínio, o que é muito comum com o uso de servidores em CDN, basta você adicionar o domínio na sequência:

```sh
httrack https://heavymetal-ns.github.io \
+https://maxcdn.bootstrapcdn.com \
+https://cdnjs.cloudflare.com \
+https://code.jquery.com
```

No exemplo acima, o espelhamento será feito em [heavymetal-ns.github.io](https://heavymetal-ns.github.io){:target="_blank"} e os outros domínios serão acessados apenas quando houver requisições no código do site principal.

Caso você não queira inspecionar o código das páginas e já deseje copiar todos os arquivos lincados, pode fazer assim:

```sh
httrack -e https://github.com
```

O parâmetro `-e` (--go-everywhere) indica que o HTTrack pode seguir qualquer link na web. Cuidado com isso.

Algo muito útil, também é a atualização do espelhamento com `--update` ou a continuação com `--continue`. E, se for bloqueado pelo robots.txt do site, pode ignorá-lo com `-sN` e seguir qualquer URL pública.


## Tracker

{: .file-excerpt }
/usr/local/bin/track
:	```sh
	#!/bin/bash
	# Author: Natan Felles <natanfelles@gmail.com>
	# Description: Use HTTrack with pre-defined options
	# Local: /usr/local/bin/track

	if  ! type httrack >> /dev/null ; then
		echo "HTTrack is not installed. Install it and try again.";
		exit 1;
	fi

	#if  ! "$1" ; then
		echo -n "Enter the URL's (you can use + and -): ";
		read URLS;
	#fi

	httrack \
	--robots "0" \
	--preserve \
	--footer "" \
	--user-agent "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:51.0) Gecko/20100101 Firefox/51.0" \
	$URLS;

	```
